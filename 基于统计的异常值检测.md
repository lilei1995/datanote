## 基于统计的异常值检测

这里将基于统计的作为一类异常检测技术，方法比如多，下面主要介绍MA和3-Sigma。

## MA滑动平均法

识别数据不规则性的最简单的方法是标记偏离分布的数据点，包括平均值、中值、分位数和模式。假定异常数据点是偏离平均值的某个标准偏差，那么我们可以计算时间序列数据滑动窗口下的局部平均值，通过平均值来确定偏离程度。这被技术称为**滑动平均法**(moving average，MA)，旨在平滑短期波动并突出长期波动。滑动平均还包括累加移动平均、加权移动平均、指数加权移动平均、双指数平滑、三指数平滑等，在数学上，nn周期简单移动平均也可以定义为“低通滤波器”。

缺点：

- 数据中可能存在与异常行为类似的噪声数据，所以正常行为和异常行为之间的界限通常不明显；
- 异常或正常的定义可能经常发生变化，因为恶意攻击者不断适应自己。因此，基于移动平均值的阈值可能并不总是适用。

## 3-Sigma

3-Sigma原则又称为拉依达准则，该准则定义如下：

**假设一组检测数据只含有随机误差，对原始数据进行计算处理得到标准差，然后按一定的概率确定一个区间，认为误差超过这个区间的就属于异常值。**

![img](http://www.csuldw.com/assets/articleImg/2019/3-sigma-all.png)

使用3-Sigma的前提是数据服从正态分布（当然如果x不服从正态分布，可以使用log将其转为正态分布，详细参阅[Log Normal Distribution](https://en.wikipedia.org/wiki/Log-normal_distribution)），满足这个条件之后，在3-Sigma范围(μ−3σ,μ+3σ)(μ−3σ,μ+3σ)内`99.73%`的为正常数据，其中σσ代表标准差,μμ代表均值，x=μx=μ为图形的对称轴。下面是3-Sigma的Python实现。

```
#3-sigma识别异常值
def three_sigma(df_col):  
'''   
df_col：DataFrame数据的某一列 
'''  
rule = (df_col.mean() - 3 * df_col.std() > df_col) | (df_col.mean() + 3 * df_col.std() < df_col)   
index = np.arange(df_col.shape[0])[rule]    
outrange = df_col.iloc[index]    
return outrange
```

对于异常值检测出来的结果，有多种处理方式，如果是时间序列中的值，那么我们可以认为这个时刻的操作属于异常的；如果是将异常值检测用于数据预处理阶段，处理方法有以下四种：

1. 删除带有异常值的数据；
2. 将异常值视为缺失值，交给缺失值处理方法来处理；
3. 用平均值进行修正；
4. 当然我们也可以选择不处理。

## 基于密度的异常检测

基于密度的异常检测有一个先决条件，即正常的数据点呈现“*物以类聚”*的聚合形态，正常数据出现在密集的邻域周围，而异常点偏离较远。对于这种场景，我们可以计算得分来评估最近的数据点集，这种得分可以使用Eucledian距离或其它的距离计算方法，具体情况需要根据数据类型来定：**类别型或是数字型**。

### 局部异常因子算法

### Local Outlier Factor原理

**局部异常因子算法，全称Local Outlier Factor（简写LOF)**。LOF算法是一种无监督的异常检测方法，它计算给定数据点相对于其邻居的局部密度偏差。每个样本的异常分数称为局部异常因子。异常分数是局部的，取决于样本相对于周围邻域的隔离程度。确切地说，局部性由`k`近邻给出，并使用距离估计局部密度。通过将样本的局部密度与其邻居的局部密度进行比较，可以识别密度明显低于其邻居的样本,，这些样本就被当做是异常样本点。

#### **算法原理如下**：

1. 1. 计算k-distance of p：计算点`p`的第`k`距离，也就距离样本点`p`第`k`远的点的距离，不包括`p`;
   2. 计算k-distance neighborhood of p：计算点`p`的第`k`邻域距离，就是`p`的第`k`距离以内的所有点，包括第`k`距离;
   3. 计算reach-distance：可达距离，若小于第`k`距离，则可达距离为第`k`距离，若大于第k距离，则可达距离为真实距离，公式如下(说明:d(p,o)d(p,o)为`p`到`o`的距离)：
        ![1569653331884](C:\Users\83759\AppData\Roaming\Typora\typora-user-images\1569653331884.png)  (1)
   点o到点p的第k可达距离，至少是点o的第k距离，或者为o与p间的真实距离。
   4. 4，计算local reachability density：局部可达密度
                    ![1569653259210](C:\Users\83759\AppData\Roaming\Typora\typora-user-images\1569653259210.png)        (2)

   ​                 表示点p的第k邻域内点到点p的平均可达距离的倒数。
      5，计算local outlier factor:局部离群因子.
   ​      ![1569653280286](C:\Users\83759\AppData\Roaming\Typora\typora-user-images\1569653280286.png)   (3)

   表示点p的邻域点Nk(p)的局部可达密度与点p的局部可达密度之比的平均数。

   

### 实例Demo

**Step1: 导入数据集**。为了方便起见，这里采用了**Kaggle里面的[Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud/version/3)作为实验数据集，**其中包含492个正样本（异常样本），284315个正常样本（负样本）。首先，我们先导入数据集（注意：`creditcard.csv`文件在[这里](https://www.kaggle.com/mlg-ulb/creditcardfraud/version/3)下载)。

```
import pandas as pd
importnumpy as np
creditcard_data = pd.read_csv("creditcard.csv")
```

**Step2：数据集转换**。加载数据集，我们需要将数据集中的特征数据X提取出来，Y作为类别标签，在无监督算法的训练过程中不需要用到，在模型评估阶段再使用。这里不得不吹捧一下pandas，操作起来真的特别方便，代码如下：

```
from sklearn.metrics import classification_report, accuracy_score
from sklearn.neighbors import LocalOutlierFactor
state = np.random.RandomState(42)
columns = creditcard_data.columns.tolist()
columns = [c for c in columns if c not in ["Class"]]
target = "Class"
state = np.random.RandomState(42)
X = creditcard_data[columns]
Y = creditcard_data[target]
X_outliers = state.uniform(low=0, high=1, size=(X.shape[0], X.shape[1]))
```

Step3: **模型训练与预测。**得到了训练数据之后，下面我们通过条用sklearn的算法库来实现模型的训练和预测。

```
classifiers = {   
"Local Outlier Factor":LocalOutlierFactor(n_neighbors=20, algorithm='auto',                                        leaf_size=30, metric='minkowski',                                       p=2, metric_params=None, contamination=0.01)
}
def train_model(clf, train_X):    
#Fit the train data and find outliers    
y_pred = clf.fit_predict(X)   
scores_prediction = clf.negative_outlier_factor_   
return y_pred, clf   
y_pred, clf = train_model(clf=classifiers["Local Outlier Factor"], train_X=X)
```

Step4: **模型评估。**为了验证LOF算法的准确度，我们可以采用预测的异常数据和真实的异常数据进行比对。注意，通过上述模型预测的结果为`1`（正常样本）和`-1`（异常样本），所以在模型评估的时候，需要对预测的label进行转换，具体实现如下：

```
def evaluation_model(y_pred, y_label, clf_name):   
'''   
y_pred: prediction label   
y_label: true lable    
clf_name: string   
'''    
#transform anomaly label   
y_rebuild = [0 if y == 1 else 1 for y in y_pred ]     
n_errors = (y_rebuild != Y).sum()      
#Classification Metrics    
print("{}: {}".format(clf_name, n_errors))   
print("Accuracy Score :", accuracy_score(Y, y_rebuild))   
print("Classification Report :")   
print(classification_report(Y, y_rebuild))
s = y_pred
evaluation_model(y_pred, Y, clf_name="LOF")
```

当然，基于密度的还有**KNN算法（有监督）**，kNN是一种简单的非参数化机器学习算法，使用距离来度量相似性进而对数据进行分类，例如Eucledian，Manhattan，Minkowski或Hamming distance等。关于KNN算法，可以参考笔者的另一篇文章：[机器学习算法-K最近邻从原理到实现](https://www.csuldw.com/2015/05/21/2015-05-21-KNN/)。那么，怎么将KNN应用到异常检测中呢？比较简单的做法是计算预测数据与最近的K个样本点的距离和，然后根据阈值进行异常样本的判别。这类方法有一种明显的缺点，如果异常样本数据较多，并且单独成簇的话，最后得到的结果则不太乐观。

## 基于聚类的异常检测

通常，类似的数据点往往属于相似的组或簇，由它们与局部簇心的距离决定。正常数据距离簇中心的距离要进，而异常数据要原理簇的中心点。聚类属于无监督学习领域中最受欢迎的算法之一，关于聚类异常检测可分为两步：

1. 利用聚类算法聚类;
2. 计算各个样本点的异常程度：每个点的异常程度等于到最近类中心点的距离。

缺点：

- 如果异常数据自己成簇，将难以区分异常；

### 基于K-Means聚类的异常检测

K-Means是一种广泛使用的聚类算法，它创建了`k`个类似的数据点群体，不属于这些簇（远离簇心）的数据样例则有可能被标记为异常数据。聚类算法较多，如DBSCAN、层次聚类等，

k-Means算法是一种聚类算法，它是一种无监督学习算法，目的是将相似的对象归到同一个蔟中。蔟内的对象越相似，聚类的效果就越好。聚类和分类最大的不同在于，分类的目标事先已知，而聚类则不一样。其产生的结果和分类相同，而只是类别没有预先定义。

#### 算法原理

设计的目的：**使各个样本与所在簇的质心的均值的误差平方和达到最小**（这也是评价K-means算法最后聚类效果的评价标准）。

![1569654258827](C:\Users\83759\AppData\Roaming\Typora\typora-user-images\1569654258827.png)

**K-均值聚类**

- 优点：容易实现
- 缺点：可能收敛到局部最小值，在大规模数据上收敛较慢
- 适合数据类型：数值型数据

### 步骤

1. 创建k个点作为k个簇的起始质心（经常随机选择）。
2. 分别计算剩下的元素到k个簇中心的相异度（距离），将这些元素分别划归到相异度最低的簇。
3. 根据聚类结果，重新计算k个簇各自的中心，计算方法是取簇中所有元素各自维度的算术平均值。
4. 将D中全部元素按照新的中心重新聚类。
5. 重复第4步，直到聚类结果不再变化。
6. 最后，输出聚类结果。

**伪代码**

```
创建k个点作为K个簇的起始质心（经常随机选择）
当任意一个点的蔟分配结果发生变化时（初始化为True）
对数据集中的每个数据点，重新分配质心		
对每个质心			
计算质心到数据点之间的距离	
将数据点分配到距其最近的蔟	
对每个蔟，计算蔟中所有点的均值并将均值作为新的质心
```

**实现**

因为我们用到的是数值类型数据，这里需要编写一个加载数据集的函数，其返回值是一个矩阵。下面代码应写在一个py文件里，我这里写在kMeans.py文件中。

首先引入相关的头文件：numpy

```
from numpy import *
```

**数据集加载代码**

```
# 加载数据集文件，没有返回类标号的函数def loadDataSet(fileName):  
dataMat = []   
openfile = open(fileName)    
for line in openfile.readlines():    
curLine = line.strip().split('\t')      
floatLine = map(float,curLine)   
dataMat.append(floatLine)   
return dataMat
```

因为在k均值算法中要计算点到质心的距离，所以这里将距离计算写成一个函数，计算欧几里得距离公式：

![1569654347992](C:\Users\83759\AppData\Roaming\Typora\typora-user-images\1569654347992.png)

**函数代码如下：**

```
# 计算两个向量的欧氏距离def distEclud(vecA,vecB):    return sqrt(sum(power(vecA-vecB,2)))
```

**接下来初始化k个蔟的质心函数centroid**

```
# 传入的数据时numpy的矩阵格式
def randCent(dataMat, k): 
n = shape(dataMat)[1]   
centroids = mat(zeros((k,n)))     
for j in range(n):       
minJ = min(dataMat[:,j]) # 找出矩阵dataMat第j列最小值     
rangeJ = float(max(dataMat[:,j]) - minJ) #计算第j列最大值和最小值的差   
#赋予一个随机质心，它的值在整个数据集的边界之内     
centroids[:,j] = minJ + rangeJ * random.rand(k,1)  
return centroids #返回一个随机的质心矩阵
```

**K-means算法实现**

```
#返回的第一个变量时质心，第二个是各个簇的分布情况
def kMeans(dataMat,k,distE = distEclud , createCent=randCent):   
m = shape(dataMat)[0]    # 获得行数m  
clusterAssment = mat(zeros((m,2))) # 初试化一个矩阵，用来记录簇索引和存储误差                                   centroids = createCent(dataMat,k) # 随机的得到一个质心矩阵蔟    clusterChanged = True  
while clusterChanged:     
clusterChanged = False     
for i in range(m):    #对每个数据点寻找最近的质心        
minDist = inf; minIndex = -1           
for j in range(k): # 遍历质心蔟，寻找最近的质心                  
distJ1 = distE(centroids[j,:],dataMat[i,:]) #计算数据点和质心的欧式距离               
if distJ1 < minDist:                    
minDist = distJ1                    
minIndex = j           
if clusterAssment[i,0] != minIndex:              
clusterChanged = True          
clusterAssment[i,:] = minIndex, minDist**2     
print centroids    
for ci in range(k):   #更新质心，将每个族中的点的均值作为质心        
index_all = clusterAssment[:,0].A   #取出样本所属簇的索引值          
value = nonzero(index_all==ci)    #取出所有属于第ci个簇的索引值           
sampleInClust = dataMat[value[0]]     #取出属于第i个簇的所有样本点            centroids[cent,:] = mean(sampleInClust, axis=0)   
return centroids, clusterAssment
```

虽然K-Means算法原理简单，但是也有自身的缺陷：

- 首先，聚类的簇数K值需要事先给定，但在实际中这个 K 值的选定是非常难以估计的，很多时候，事先并不知道给定的数据集应该分成多少个类别才最合适。
- Kmeans需要人为地确定初始聚类中心，不同的初始聚类中心可能导致完全不同的聚类结果，不能保证Ｋ-Means算法收敛于全局最优解。
  - 针对此问题，在K-Means的基础上提出了二分K-means算法。该算法首先将所有点看做是一个簇，然后一分为二，找到最小SSE的聚类质心。接着选择其中一个簇继续一分为二，此处哪一个簇需要根据划分后的SSE值来判断。
- 对离群点敏感。
- 结果不稳定 （受输入顺序影响）。
- 时间复杂度高O(nkt)，其中n是对象总数，k是簇数，t是迭代次数。

## 测试

在控制台调用上述函数，执行下列命令：

```
dataMat = mat(loadDataSet('testSet.txt'))
kMeans(dataMat, 4)
```

运行上面代码后，可以看到`print`处输出的结果：

```
[[-3.66087851  2.30869657]
 [ 3.24377288  3.04700412]
 [ 2.52577861 -3.12485493]
 [-2.79672694  3.19201596]]
[[-3.78710372 -1.66790611]
 [ 2.6265299   3.10868015]
 [ 1.62908469 -2.92689085]
 [-2.18799937  3.01824781]]
[[-3.53973889 -2.89384326]
 [ 2.6265299   3.10868015]
 [ 2.65077367 -2.79019029]
 [-2.46154315  2.78737555]]
```

测试的时候取的k值为4，即簇的个数为4，所以经过3次迭代之后K-均值算法就收敛了。质心会保存在第一个返回值中，第二个是每个点的簇分布情况。k=4是，聚类结果如下：

![img](https://www.csuldw.com/assets/articleImg/k_clusters4.png)

附数据集：https://github.com/csuldw/MachineLearning/blob/master/Kmeans/data/testSet.txt

### 1.K-Means算法K值如何选择？

《大数据》中提到：给定一个合适的类簇指标，比如平均半径或直径，只要我们假设的类簇的数目等于或者高于真实的类簇的数目时，该指标上升会很缓慢，而一旦试图得到少于真实数目的类簇时，该指标会急剧上升。

- 簇的直径是指簇内任意两点之间的最大距离。
- 簇的半径是指簇内所有点到簇中心距离的最大值。

### 2. 如何优化K-Means算法搜索的时间复杂度？

可以使用K-D树来缩短最近邻的搜索时间（NN算法都可以使用K-D树来优化时间复杂度）。

### 3. 如何确定K个簇的初始质心？

1) 选择批次距离尽可能远的K个点

首先随机选择一个点作为第一个初始类簇中心点，然后选择距离该点最远的那个点作为第二个初始类簇中心点，然后再选择距离前两个点的最近距离最大的点作为第三个初始类簇的中心点，以此类推，直至选出K个初始类簇中心点。

2) 选用层次聚类或者Canopy算法进行初始聚类，然后利用这些类簇的中心点作为KMeans算法初始类簇中心点。

聚类扩展：密度聚类、层次聚类。



## OneClassSVM的异常检测

### 原理

SVM（支持向量机）是一种用于检测异常的另一种有效的技术。SVM通常与监督学习相关联，但是存在可以用于将异常识别为无监督问题（其中训练数据未被标记）的扩展（OneClassCVM）。算法学习软边界以便使用训练集对正常数据实例进行聚类，然后，使用测试实例，它调整自身以识别落在学习区域之外的异常。根据使用情况，异常检测器的输出可以是数字标量值，用于过滤特定于域的阈值或文本标签（如二进制/多标签）。

### 实例

本实例使用的数据与Local Outlier Factor一样，这里暂且不重复写入了。下面，简单介绍下OneClassSVM算法模型训练部分，其余的与上述类似。代码如下：

```
classifiers = {   
"Support Vector Machine":OneClassSVM(kernel='rbf', degree=3, gamma=0.1,nu=0.05,                                          max_iter=-1, random_state=state)}
def train_model(clf, train_X):   
#Fit the train data and find outliers   
clf.fit(X)    
y_pred = clf.predict(X)    
return y_pred,clf   
y_pred,clf = train_model(clf=classifiers["Support Vector Machine"], train_X=X)
```

SVM训练时间较长，具体效果需要看算法与数据集的拟合程度。

## iForest异常检测

### 原理

iForest（isolation forest，孤立森林）算法是一种基于Ensemble的快速异常检测方法，具有线性时间复杂度和高精准度，该算法是刘飞博士在莫纳什大学就读期间由陈开明(Kai-Ming Ting)教授和周志华(Zhi-Hua Zhou)教授指导发表的，与LOF、OneClassSVM相比，其占用的内存更小、速度更快。算法原理如下：

![img](http://www.csuldw.com/assets/articleImg/2019/iforest.png)

异常score计算公式如下：

![1569653980797](C:\Users\83759\AppData\Roaming\Typora\typora-user-images\1569653980797.png)

其中h(x)h(x) 为路径长度，可以通过公式 H(k)=ln(k)+ξH(k)=ln(k)+ξ来估计，ξ是欧拉常数，其值为`0.5772156649`。E(h(x))E(h(x))是iForest中xx在不同树中的路径长度h(x)h(x)的平均值，c(n)c(n)是样本点为nn时BST的平均路径长度，c(n)=2H(n−1)−2(n−1)nc(n)=2H(n−1)−2(n−1)n,用来对结果进行归一化处理.

- 当E(h(x))E(h(x))趋近于00时,s趋近于1，异常的概率越大；
- 当E(h(x))E(h(x))趋近于n−1n−1时, s趋近于0，正常的概率越大.
- 当E(h(x))E(h(x))趋近于c(n)c(n)时, s趋近于0.5；

### 实例

这里简单介绍下iForest模型训练部分，数据加载和模型评估的方法与上述类似。算法部分的代码如下：



```
classifiers = {    
"Isolation Forest":IsolationForest(n_estimators=100, max_samples=len(X),                                        contamination=0.005,random_state=state, verbose=0)
}
def train_model(clf, train_X):   
#Fit the train data and find outliers    
clf.fit(X)   
#scores_prediction = clf.decision_function(X)    
y_pred = clf.predict(X)    
return y_pred, clf   
y_pred,clf = train_model(clf=classifiers["Isolation Forest"], train_X=X)
```

使用上面的参数在笔者的笔记本上训练时间只花了1min 12s，相比于SVM的确要快很多。

## PCA+MD异常检测

PCA（主成分分析）是一种常用的线性降维方法，通过计算数据（中心化后的数据）协方差矩阵的特征值和特征向量来得到数据的主要成分，**最大特征值λkλk对应的特征向量αkαk为数据方差最大的方向**，相信很多人都用过，笔者先前的文章[PCA主成分分析Python实现](http://www.csuldw.com/2016/02/28/2016-02-28-pca/)中也有介绍，那么如何使用PCA进行异常检测呢？方法如下：

1. 通过PCA将数据映射到低维特征空间之后，在各个特征空间不同维度上查看每个数据点跟其它数据的偏差，如果数据距离该超平面很远，那么该数据可能属于异常数据.
2. 对于降维后的数据，通过观察各样本点到样本中心的MD距离来衡量，如果距离太大（可根据实际情况设置阈值），就可以判断是异常值。

![1569654115673](C:\Users\83759\AppData\Roaming\Typora\typora-user-images\1569654115673.png)



## AutoEncoder异常检测

AutoEncoder（自编码器，简称AE）是一种无监督的深度学习模型，原理比较简单：对于输入样本xx，首先通过encoder编码器ff将其压缩为维度较低的yy，然后通过decoder解码器gg对每个样本点进行重建，还原到原来的维度，得到zz。整个训练模型的目的就是减少重构error，得到的hidden层的yy，相当于降维后的数据。整个framework如下：

![img](http://www.csuldw.com/assets/articleImg/2019/autoencoder.png)

AutoEncoder本质上与PCA类似，AutoEncoder可以用作降维，区别在于PCA属于线性变换，而AutoEncoder属于非线性变换。在异常检测应用上，AE通过计算重建数据与输入数据的重建误差作为异常的衡量，如果样本都是数值型，可以用MSE或MAE作为衡量指标，样本的重建误差越大，则表明异常的可能性越大。关于如何使用autoEncoder，这里暂且不介绍了，后续可能会单独写一篇。

## Conclusion

本文介绍了八种常用的无监督异常检测方法，主要偏向于理论的说明，对于有label标记的数据，我们还可以采用分类算法进行训练和预测，这里就不横向扩宽了。实际项目中，前期标注数据比较少，我们可以采用无监督方式，随着标注数据的增多，后面可以使用监督学习方法，并将无监督与有监督进行结合。OK，这篇文章暂且到此为止，后续相关的实践，笔者也会逐步分享出来，感谢光顾。